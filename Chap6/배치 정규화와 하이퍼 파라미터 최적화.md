## 배치 정규화

#### 배치 정규화를 하는 이유

- 학습의 속도를 개선
- 초기값에 크게 의존하지 않음
- 오버피팅을 억제

미니배치 **데이터의 분포가 평균이 0, 분산이 1**이 되도록 정규화

<img src="https://user-images.githubusercontent.com/58063806/89436264-f5551100-d780-11ea-9f7e-60b9ec4a4af6.JPG" width=30% />

순서대로 **평균, 분산, 정규화된 미니배치 데이터** 

이러한 처리를 활성화 함수의 앞 또는 뒤에 삽입함으로써 데이터 분포가 덜 치우치게 할 수 있음

또한 **배치 정규화 계층마다 정규화된 데이터에 고유한 확대와 이동 변환을 수행**하는데  

<img src="https://user-images.githubusercontent.com/58063806/89436693-8b893700-d781-11ea-94b5-1a4ec2866518.JPG" width=30% />

**r(확대)는 1, β(이동)는 0부터 시작해서 학습하면서 적합한 값으로 조정**

#### 배치 정규화의 효과 

<img src="https://user-images.githubusercontent.com/58063806/89488581-5f9e9d80-d7e3-11ea-8f12-a4f7a6236b8e.PNG" width=100% />

가중치 초기값의 표준편차를 바꿔가며 실험

거의 모든 경우에 **배치 정규화를 사용할 때의 학습 진도가 빠른 것**으로 나타남

**배치 정규화가 안되있는 경우는 초기값이 잘 분포되어 있지 않으면 학습이 전혀 진행되지 않는 경우도 있음** 

결과적으로 **배치 정규화를 사용하면 학습이 빨라지며, 가중치 초기값에 크게 의존하지 않아도 됨**

## 오버피팅

다음의 경우에 주로 오버피팅이 일어남

- 매개변수가 많고 표현력이 높은 모델
- 훈련 데이터가 적음

위의 조건을 충족시키기 위해 MNIST 데이터셋의 훈련 데이터 중 300개만 사용(훈련 데이터 적음)하고, 7층 네트워크를 사용(복잡성 높임)

<img src="https://user-images.githubusercontent.com/58063806/89495298-f888e500-d7f2-11ea-941f-ea1e6ce2a5f9.PNG" width=60% />

위의 결과를 보면 **100 에폭을 지나는 무렵부터 정확도가 거의 100%이지만 시험 데이터와는 큰 차이를 보임(훈련 데이터에만 적응해버린 결과, 오버피팅이 일어남)**

### 가중치 감소

오버피팅을 억제하는 방법으로써 학습 과정에서 **큰 가중치에 대해서 그에 상응하는 큰 페널티를 부과**

가중치의 제곱 노름(L2 노름)을 손실 함수에 더함으로써 가중치가 커지는 것을 억제

<img src="https://user-images.githubusercontent.com/58063806/89496695-cc229800-d7f5-11ea-9a43-e1fe86330ee2.PNG" width=50% />

**가중치의 각 원소들의 제곱을 더하고 루트**

이에 따른 **가중치 감소는 1/2 x λ x W^2**이 됨(이것을 **모든 가중치 각각의 손실 함수에 더함**)

λ - 정규화의 세기를 조절하는 하이퍼 파라미터**(크게 설정할수록 큰 가중치에 대한 페널티가 커짐)**

1/2 - 가중치 감소의 미분결과인 λW를 조정하는 역할의 상수

#### λ를 0.1로 설정했을 때

<img src="https://user-images.githubusercontent.com/58063806/89497404-40aa0680-d7f7-11ea-82bd-fafc0f27676e.PNG" width=60% />

훈련 데이터와 시험 데이터 간의 정확도 차이는 여전히 존재하지만 **가중치 감소를 이용하지 않은 결과와 비교했을때에는 차이가 줄음** 

### 드롭아웃

신경망 모델이 복잡해지면 가중치 감소만으로는 대응하기 어려워지고 이때 사용하는 방법

훈련 때 **은닉층의 뉴런을 무작위로 골라 삭제(삭제된 뉴런은 신호를 전달하지 않음)**

**훈련 때**는 데이터를 흘릴 때마다 **삭제할 뉴런을 무작위로 선택**, **시험 때**는 **모든 뉴런에 신호를 전달**(단, **시험 때는 각 뉴런의 출력에 훈련 때 삭제 안 한 비율을 곱해서 출력)**  

<img src="https://user-images.githubusercontent.com/58063806/89498181-bc588300-d7f8-11ea-906f-2094901849f9.PNG" width=60% />

```python
class Dropout:
    
    def __init__(self, dropout_ratio=0.5):
        self.dropout_ratio = dropout_ratio
        self.mask = None

    def forward(self, x, train_flg=True):
        if train_flg:
            self.mask = np.random.rand(*x.shape) > self.dropout_ratio
            return x * self.mask
        else:
            return x * (1.0 - self.dropout_ratio)

    def backward(self, dout):
        return dout * self.mask
```

self.mask - x와 형상이 같은 배열을 무작위로 생성하고 그 값이 dropout_ratio보다 큰 원소만 True로 설정

역전파 때는 ReLU와 같이 **순전파 때 신호를 통과시키는 뉴런은 역전파 때도 신호를 그대로 통과**시키고, **순전파 때 신호를 통과시키지 않은 뉴런은 역전파 때도 신호를 차단**함

<img src="https://user-images.githubusercontent.com/58063806/89499098-65ec4400-d7fa-11ea-8c9c-8adbe8c52891.PNG" width=60% />

훈련 데이터와 시험 데이터 간의 정확도 차이가 줄어들고, 훈련 데이터에 대한 정확도가 100%에 도달하지도 않게 됨

**앙상블 학습  - 개별적으로 학습시킨 여러 모델의 출력을 평균 내어 추론하는 방식**

신경망의 맥락에서 보면 같은 구조의 네트워크 5개를 준비해서 따로 학습시키고 시험 때는 5개의 출력을 평균 내에 답함**(앙상블 학습을 수행하면 신경망의 정확도가 몇% 정도 개선)**

**앙상블 학습과 드롭아웃은 밀접**하다고 볼 수 있는데 드롭아웃에서 **학습 때 뉴런을 무작위로 삭제하는 행위(=매번 다른 모델을 학습)**, **추론 때에 뉴런의 출력에 삭제한 비율을 곱함(=앙상블 학습에서 모델의 평균을 내는 것)**

## 적절한 하이퍼 파라미터 값 찾기

하이퍼 파라미터에는 **각 층의 뉴런 수, 배치 크기, 매개변수 갱신 시의 학습률, 가중치 감소** 등이 있음

### 검증 데이터

**시험 데이터를 사용하여 하이퍼 파라미터를 조정**하면 하이퍼 파라미터 값이 **시험 데이터에 오버피팅**되고 이로 인해 **하이퍼 파라미터의 성능을 평가하기 위한 데이터**가 필요한데 이것이 검증 데이터임

```python
# 20%를 검증 데이터로 분할
validation_rate = 0.20
validation_num = int(x_train.shape[0] * validation_rate)
# 분리하기 전에 입력 데이터와 정답 레이블을 뒤섞음(데이터셋 안의 데이터 치우침을 방지)
x_train, t_train = shuffle_dataset(x_train, t_train)
x_val = x_train[:validation_num]
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]
t_train = t_train[validation_num:]
```

**검증 데이터를 얻기 위해 훈련 데이터 중 20%를 분리**함

### 최적화

**대략적인 범위를 설정**하고 그 범위에서 **무작위로 하이퍼 파라미터 값을 골라낸 후, 그 값으로 정확도를 평가하는 것을 반복**하며 **최적 값의 범위를 좁혀가는 것**

10의 거듭제곱 단위(로그 스케일)로 범위를 지정

하이퍼 파라미터를 최적화 할때는 딥러닝 학습에는 **며칠이나 몇 주 이상정도의 오랜 시간이 걸리므로 학습을 위한 에폭을 작게 하여, 1회 평가에 걸리는 시간을 단축하는 것이 효과적**

- 하이퍼 파라미터 값을 범위를 설정
- 설정된 범위에서 하이퍼 파라미터 값을 무작위 추출
- 샘플링한(무작위 추출) 하이퍼 파라미터 값을 사용하여 학습하고, 검증 데이터로 정확도를 평가
- 샘플링과 평가를 반복하면서 정확도 결과를 보며 하이퍼 파라미터의 범위를 좁힘

```python
weight_decay = 10 ** np.random.uniform(-8, -4) # 가중치 감소 계수
    lr = 10 ** np.random.uniform(-6, -2) # 학습률
```

<img src="https://user-images.githubusercontent.com/58063806/89506649-67bc0480-d806-11ea-9eb2-bdd272dc90f0.PNG" width=70% />

실선 - 검증 데이터에 대한 정확도

점선 - 훈련 데이터에 대한 정확도

<img src="https://user-images.githubusercontent.com/58063806/89507293-46a7e380-d807-11ea-90ae-519af335b78d.PNG" width=80% />

위와 같은 결과를 보면서 범위를 좁혀나가야 함