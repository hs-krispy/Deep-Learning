## 데이터 활용

기계학습에서는 **사람의 개입을 최소화**하고 수집한 **데이터로부터 패턴**을 찾으려고 시도

이미지에서 '5'라는 숫자를 인식하는 프로그램을 구현할 때 알고리즘을 밑바닥부터 구현하는 것보다는 **이미지에서 특징(입력 데이터에서 본질적인 데이터를 정확히 추출하도록 설계된 변환기)을 추출**하고 그 **특징의 패턴을 기계학습 기술로 학습**하는 방법이 더 좋음 

이미지의 특징은 보통 벡터로 기술하는데 **이미지를 벡터로 변환할 때 사용하는 특징은 사람이 설계**하고 **데이터로부터 규칙을 찾아내는 역할은 기계가 담당**함

반면 **딥러닝은 종단간 기계학습이라고도 하며 데이터(입력)에서 목표한 결과(출력)를 사람의 개입 없이 얻음** 

훈련 데이터 - 최적의 매개변수를 찾음

시험 데이터 - 훈련된 모델의 성능을 평가

범용 능력 - **아직 보지 못한 데이터**(훈련 데이터에 포함되지 않음)로도 **문제를 올바르게 풀어내는 능력**으로 이를 얻는 것이 기계학습의 최종 목표

오버피팅 - 하나의 데이터셋으로만 매개변수의 학습과 평가를 수행하면 해당 데이터셋은 제대로 맞히더라도 다른 데이터셋에서는 성능이 엉망일 수도**(한 데이터셋에서만 지나치게 최적화된 상태)** 있음

## 손실 함수

신경망 학습에서는 **현재의 상태를 '하나의 지표'로 표현**하고 이를 기준으로 **최적의 매개변수 값을 탐색**하는데 이때 사용하는 지표이며 **신경망 성능의 '나쁨'을 나타내는 지표**로, 현재의 **신경망이 훈련 데이터를 얼마나 잘 처리하지 '못'하느냐**를 나타냄

**(-만 곱해주면 성능이 얼마나 좋은가하는 지표로 변화가능)**

일반적으로 **오차제곱합과 교차 엔트로피 오차**를 사용함

### 오차제곱합

<img src="https://user-images.githubusercontent.com/58063806/88127817-8e2b4e80-cc0f-11ea-9be5-e78143b71312.png" width=55%/>

yk - 신경망의 출력(신경망이 추정한 값)

tk - 정답 레이블(정답에 해당하는 인덱스의 원소만 1, 원-핫 인코딩)

k - 데이터의 차원 수를 나타냄

오차제곱합은 각 원소의 출력과 정답 레이블의 차를 제곱한 후, 그 총합을 구함

```python
import numpy as np

def sum_squares_error(y, t):
    return 0.5 * np.sum((y - t) ** 2)

y1 = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])
# 정답 2, 신경망의 출력 2에서 가장 높음
y2 = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])
# 정답 2, 신경망의 출력 7에서 가장 높음
t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])
print(sum_squares_error(y1, t)) # 0.09750000000000003 출력
print(sum_squares_error(y2, t)) # 0.5975 출력
```

결과를 보면 첫 번째 예의 **손실 함수 쪽 출력이 작으며 오차가 적은 것을 알 수 있음(정답에 더 가까움)**

### 교차 엔트로피 오차

<img src="https://user-images.githubusercontent.com/58063806/88127821-8ec3e500-cc0f-11ea-9416-138f80436568.png" width=55%/>

여기서 log의 밑이 e임

yk - 신경망의 출력(신경망이 추정한 값)

tk - 정답 레이블(정답에 해당하는 인덱스의 원소만 1, 원-핫 인코딩)

```python
y1 = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])
# 정답 2, 신경망의 출력 2에서 가장 높음
y2 = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])
# 정답 2, 신경망의 출력 7에서 가장 높음
t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])
def cross_entropy_error(y, t):
    delta = 10 ** -7 
    return -np.sum(t * np.log(y + delta))
print(cross_entropy_error(y1, t)) # 0.510825457099338 출력
print(cross_entropy_error(y2, t)) # 2.302584092994546 출력
```

**delta - np.log()에 0이 들어가서 -무한대가 되는 것을 방지하고자 더해주는 아주 작은 값**

결과를 보면 첫 번째 예의 **교차 엔트로피 오차가 더 적음(정답일 가능성이 높음)**을 알 수 있고 이는 **오차제곱합의 판단과 일치**함

### 미니배치

데이터의 개수가 커지면 일일이 손실함수를 계산하는 것이 비현실적이기 때문에 **데이터의 일부를 추려(전체의 근사치로 이용)** 학습을 수행하는 것

<img src="https://user-images.githubusercontent.com/58063806/88136011-59c18d80-cc23-11ea-93b5-0718325c6cac.PNG" width=55%/>

데이터가 N개 

y - 신경망의 출력(신경망이 추정한 값)

t - 정답 레이블(정답에 해당하는 인덱스의 원소만 1, 원-핫 인코딩)

nk - n번째 데이터의 k번째 값

N으로 나눔(정규화)으로써 **평균 손실 함수**를 구함

```python
import sys, os
import numpy as np
sys.path.append("deep-learning-from-scratch")
from dataset.mnist import load_mnist

(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)
# 원-핫 인코딩으로 호출
train_size = x_train.shape[0] # 60000
batch_size = 10
batch_mask = np.random.choice(train_size, batch_size)
# 0 ~ 59999까지의 수 중 무작위로 10개
x_batch = x_train[batch_mask]
t_batch = t_train[batch_mask]
```

무작위로 나온 배열을 미니배치로 뽑을 데이터의 인덱스로 사용

```python
# 정답 레이블이 원-핫 인코딩일때 교차 엔트로피 오차 구현
def cross_entropy_error(y, t):
    delta = 10 ** -7
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    batch_size = y.shape[0]
    return -np.sum(t * np.log(y + delta)) / batch_size
# 정답 레이블이 숫자로 주어졌을때 교차 엔트로피 오차 구현
def cross_entropy_error(y, t):
    delta = 10 ** -7
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
    batch_size = y.shape[0]
    return -np.sum(t * np.log(y[np.arange(batch_size), t] + delta)) / batch_size
```

**1차원 배열인 경우 shape[0]에 열의 정보**가 들어가므로 **reshape()로 1차원을 명시해줘야 batch_size에 올바른 값**이 들어감

신경망을 학습할 때 **정확도**를 지표로 삼으면 **매개변수의 미분이 대부분의 장소에서 0**이 되고 **(매개변수의 작은 변화에는 거의 반응이 없음)** 매개변수의 변화에 반응이 있더라도 **그 값이 불연속적으로 갑자기 변화하고(계단 함수의 형식)**이로 인해 신경망 학습이 잘 이뤄지지 않음

